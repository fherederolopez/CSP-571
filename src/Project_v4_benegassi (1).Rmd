---
title: "Project"
author: "Jorge Mendez-Benegassi"
date: "2023-04-04"
output:
  pdf_document: default
  html_document: default
---

## R Markdown

```{r}

setwd("C:/Users/augus/Documents/Chicago/IIT/CSP-571 - Data Preparation/Project")
library(ggplot2)


# Load dataset
df <- read.csv("heart_data.csv")

df$age_years <- round(df$age / 365, 2)

df <- subset(df, select = -c(age, index, id))

missing_values <- sum(is.na(df))
paste("There are", missing_values, "missing values in the dataset.")

duplicate_rows <- duplicated(df)

# Subset the dataset into another with the duplicated rows
duplicate_df <- df[duplicate_rows,]
num_duplicates <- nrow(duplicate_df)
paste("There are", num_duplicates, "duplicates in the dataset.")

# Find outliers / noisy data in numerical (non-binary) features
# We first modify the variable "cardio" to be a categorical variable with two levels
df$cardio <- factor(df$cardio, levels = c(0, 1), labels = c("No", "Yes"))

# We extract the boxplot of the non-binary or non-level features
ggplot(data=df, aes(x=cardio, y=age_years, fill=cardio)) +
  geom_boxplot() +
  ggtitle("Boxplot of Age by Cardio Status")

ggplot(data=df, aes(x=cardio, y=height, fill=cardio)) +
  geom_boxplot() +
  ggtitle("Boxplot of Height by Cardio Status")

ggplot(data=df, aes(x=cardio, y=weight, fill=cardio)) +
  geom_boxplot() +
  ggtitle("Boxplot of Weight by Cardio Status")

ggplot(data=df, aes(x=cardio, y=ap_hi, fill=cardio)) +
  geom_boxplot() +
  ggtitle("Boxplot of Systolic Blood Pressure by Cardio Status")

ggplot(data=df, aes(x=cardio, y=ap_lo, fill=cardio)) +
  geom_boxplot() +
  ggtitle("Boxplot of Diastolic Blood Pressure by Cardio Status")

```

### Outliers
```{r}
cat("\nTo find anomalies, we can visually examine the boxplots and look for any data points that fall far outside the whiskers. Additionally, we can use the 'summary' function to calculate basic descriptive statistics and identify any unusual values.")

cat("To find anomalies, we can visually examine the boxplots and look for any data points that fall far outside the whiskers. Additionally, we can use the 'summary' function to calculate basic descriptive statistics and identify any unusual values.")

cat("There are no anomalies for the feature age.")
cat("There are anomalies for the feature height.")
cat("There are anomalies for the feature weight.")
cat("There are anomalies for the feature ap_hi.")
cat("There are anomalies for the feature ap_lo.")

iqr_height <- IQR(df$height)
iqr_weight <- IQR(df$weight)

paste("We may consider outliers of the features height and weight to any data point that falls more than 1.5 times the IQR below the first quartile or above the third quartile, being", iqr_height, "and", iqr_weight, "the IQR values respectively. However, following this method we find height values such as 187 cm considered outliers, therefore, it is better to consider weight and height outliers to those values with no sense with respect to the age. In this way, we will first see the distribution of height and weight values with respect to the age and extract conclusions.")

# To find outliers in height feature we are going to plot a scatter between age and height:
# Create scatter plot
plot(df$age_years, df$height)

min_age <- min(df$age_years)
max_age <- max(df$age_years)
paste("Since we have ages between", min_age, "and", max_age,", we will consider height outliers to any data point that falls out of the normal height values (range [130, 210]).")

# Rows with height values outside the range (outliers)
height_outliers <- df$height < 130 | df$height > 210

# Remove those rows
df <- df[!height_outliers, ]

# Scatter plot without those outliers
plot(df$age_years, df$height)

# To find outliers in weight feature we are going to plot a scatter between age and weight:
# Create scatter plot
plot(df$age_years, df$weight)

cat("As we can see in the scatter plot, there are no significant outliers according to the weight. There might be some high values but it can be related to obese individual. This is a relevant factor for cardiovascular desease prediction, therefore, we won't remove any weight value.")

cat("We consider outliers of the feature ap_hi (systolic) to those values higher than 180 mmHg which would correspond to a stage of hypertensive crisis, requiring immediate medical attention")

# Rows with ap_hi (systolic) values outside the range (outliers)
aphi_outliers <- df$ap_hi > 180
df <- df[!aphi_outliers, ]

cat("We consider outliers of the feature ap_lo (diastolic) to those values higher than 120 mmHg which would correspond to a stage of hypertensive crisis, requiring immediate medical attention.")

# Rows with ap_lo (diastolic) values outside the range (outliers)
aplo_outliers <- df$ap_lo > 120
df <- df[!aplo_outliers, ]
```


### Data reduction and Data transformation
```{r}
cat("We have reduced our dataset from 14 features to 12, and from 70000 observations to 68561.")

cat("We have alreay transform the age feature so that it gives us the information in years instead of days. Moreover, the target 'cardio' feature has been modified to become a categorical variable with two levels: Yes / No.")

# We transform the feature gender to be binary (1->0 and 2->1)
df$gender <- ifelse(df$gender == 1, 0, 1)

# We transform the categorical features cholesterol, gluc from 1 to 0, from 2 to 1, and from 3 to 2
df$cholesterol <- ifelse(df$cholesterol == 1, 0,
                         ifelse(df$cholesterol == 2, 1, 2))
df$gluc <- ifelse(df$gluc == 1, 0,
                         ifelse(df$gluc == 2, 1, 2))

df$cardio <- ifelse(df$cardio == "Yes", 1, 0)


############################################################
############################################################
# creating dummy variables for cholesterol and gluc
cat("It is necessary to transform all categorical values to factors for future model implementation. This includes binary attributes.")

df$cholesterol = factor(df$cholesterol)
df$gluc = factor(df$gluc)

cholesterol_dummies <- model.matrix(~ cholesterol - 1, data = df)
gluc_dummies <- model.matrix(~ gluc - 1, data = df)

# adding the dummy variables to the dataset
df <- cbind(df, cholesterol_dummies)
df <- cbind(df, gluc_dummies)

#df <- subset(df, select = -c(gluc, cholesterol))

cat("For convenience, we are going to change the order of the features so that the target is last.")
library(dplyr)

df <- select(df, gender, height, weight, ap_hi, ap_lo, cholesterol, cholesterol0, cholesterol1, cholesterol2, gluc, gluc0, gluc1, gluc2, smoke, alco, active, age_years, cardio)

cat("At this point we have five integer features corresponding to: age_years, height, weight, ap_hi, and ap_lo; four binary features corresponding to: gender, smoke, alco, and active; two categorical features with levels 0, 1, and 2, corresponding to: cholesterol and gluc; and the target feature which is categorical (yes, no): cardio.")


```
##### Discretization and normalization
```{r}

```

### Statistics
##### Repartition statistics of features
##### Statistics of categorical features
```{r}
summary_data <- summary(df)
smokers <- sum(df$smoke == 1)
percentage_smokers <- smokers*100/nrow(df)
cat("\nThe percentage of smokers is", round(percentage_smokers,2),"%.")

alcohol <- sum(df$alco == 1)
percentage_alcohol <- alcohol*100/nrow(df)
cat("\n\nThe percentage of individuals who drink alcohol is", round(percentage_alcohol,2), "%.")

men <- sum(df$gender == 1)
cat("\n\nThe number of men is", men)

women <- sum(df$gender == 0)
cat("\n\nThe number of women is", women)

gluc_normal <- sum(df$gluc == 0)
cat("\n\nThe number of individuals which glucose level is normal", gluc_normal)
cat("\n\nThe percentage of individuals which glucose level is normal", round(gluc_normal*100/nrow(df),2), "%.")

gluc_above <- sum(df$gluc == 1)
cat("\n\nThe number of individuals which glucose level is above average", gluc_above)
cat("\n\nThe percentage of individuals which glucose level is above average", round(gluc_above*100/nrow(df),2), "%.")

gluc_wellAbove <- sum(df$gluc == 2)
cat("\n\nThe number of individuals which glucose level is well above normal", gluc_wellAbove)
cat("\n\nThe percentage of individuals which glucose level is  well above normal", round(gluc_wellAbove*100/nrow(df),2), "%.")


chol_normal <- sum(df$cholesterol == 0)
cat("\n\nThe number of individuals which cholesterol level is normal", chol_normal)
cat("\n\nThe percentage of individuals which cholesterol level is normal", round(chol_normal*100/nrow(df),2), "%.")

chol_above <- sum(df$cholesterol == 1)
cat("\n\nThe number of individuals which cholesterol level is above average", chol_above)
cat("\n\nThe percentage of individuals which cholesterol level is above average", round(chol_above*100/nrow(df),2), "%.")

chol_wellAbove <- sum(df$cholesterol == 2)
cat("\n\nThe number of individuals which cholesterol level is well above normal", chol_wellAbove)
cat("\n\nThe percentage of individuals which cholesterol level is  well above normal", round(chol_wellAbove*100/nrow(df),2), "%.")


chol_percentages <- c(chol_normal*100/nrow(df), chol_above*100/nrow(df), chol_wellAbove*100/nrow(df))
labels <- c("Normal", "Above normal", "Well above normal")
chol_colors <- c("blue", "pink", "grey")
pie(chol_percentages, labels = labels, main = "Cholesterol chart", col = chol_colors)

gluc_percentages <- c(gluc_normal*100/nrow(df), gluc_above*100/nrow(df), gluc_wellAbove*100/nrow(df))
labels <- c("Normal","Above normal","Well above normal")
gluc_colors <- c("blue", "pink", "grey")
pie(gluc_percentages, labels = labels, main = "Glucose chart", col = gluc_colors)


```
#### Statistics of continuous features
```{r}
min_weight <- min(df$weight)
min_height <- min(df$height)
min_age_years <- min(df$age_years)

max_weight <- max(df$weight)
max_height <- max(df$height)
max_age_years <- max(df$age_years)

mean_weight <- mean(df$weight)
mean_height <- mean(df$height)
mean_age_years <- mean(df$age_years)

library(knitr)
stats_mat <- matrix(c(
  round(min_weight,2), round(mean_weight,2), round(max_weight,2),
  round(min_height,2), round(mean_height,2), round(max_height,2),
  round(min_age_years,2), round(mean_age_years,2), round(max_age_years,2)
), nrow = 3, byrow = TRUE, dimnames = list(
  c("Weight", "Height", "Age"),
  c("Minimum", "Mean", "Max")
))
stats_df <- as.data.frame(stats_mat)
kable(stats_df, format = "markdown")

```

### Advanced Statistics
```{r}
library(plotly)

cardio_cases <- sum(df$cardio == 1)

men_cardio  <- sum(df$gender == 1 & df$cardio == 1)
cat("\n\nThe pertentage of men with cardio problems", round(men_cardio*100/cardio_cases,2), "%")

women_cardio  <- sum(df$gender == 0 & df$cardio == 1)
cat("\n\nThe pertentage of women is with cardio problems", round(women_cardio*100/cardio_cases,2), "%")

gluc_normal_cardio <- sum(df$gluc == 0 & df$cardio == 1) * 100 / gluc_normal

gluc_above_cardio  <- sum(df$gluc == 1 & df$cardio == 1) * 100 / gluc_above

gluc_wellAbove_cardio  <- sum(df$gluc == 2 & df$cardio == 1) * 100 / gluc_wellAbove

chol_normal_cardio <- sum(df$cholesterol == 0 & df$cardio == 1) * 100 /chol_normal

chol_above_cardio <- sum(df$cholesterol == 1 & df$cardio == 1) * 100 / chol_above

chol_wellAbove_cardio <- sum(df$cholesterol == 2 & df$cardio == 1) * 100 / chol_wellAbove

labels <- c("Normal", "Above normal", "Well above normal")
cholvalues <- c(chol_normal_cardio,chol_above_cardio , chol_wellAbove_cardio)

graph0 <- barplot(cholvalues, names.arg = labels, ylab = "Percentage(%)", col = "steelblue",
        main = "Percentage of heart attack cases by cholesterol group", ylim = c(0, 100))
text(graph0, cholvalues , labels = round(cholvalues), pos = 3)


glucvalues <- c(gluc_normal_cardio,gluc_above_cardio , gluc_wellAbove_cardio)


graph <- barplot(glucvalues, names.arg = labels, ylab = "Percentage(%)", col = "steelblue",
        main = "Percentage of heart attack cases by glucose group", ylim = c(0, 80))
text(graph, glucvalues , labels = round(glucvalues), pos = 3)

```


### Standardization
```{r}
df <- subset(df, select = -c(gluc, cholesterol))

# selecting only the continuous variables
continuous_vars <- c("height", "weight", "ap_hi", "ap_lo", "age_years")

# scaling the continuous variables
df[, continuous_vars] <- scale(df[, continuous_vars])

```


### Model training
##### Feature selection
```{r}
# apply PCA to the scaled data
pca <- prcomp(df, center = TRUE, scale. = TRUE)
pca

plot(100*cumsum(pca$sdev^2)/sum(pca$sdev^2), type="b", xlab="PC", ylab="Var explained in % (cumulative)")

plot(pca$sdev^2/sum(pca$sdev^2), type="b", xlab="PC", ylab="Var explained")

cat("\nAs we can see in the cumulative plot, to explain around 89% of the variance we need the first 9 PC. We discard this technique.")

# We will plot a correlation matrix
library(corrplot)

# Calculate the correlation matrix for df
corr_matrix <- cor(df)

# Generate the correlation matrix plot using corrplot
corrplot(corr_matrix, method = "number", number.cex = 0.55)

# No sé si está bien... no sé si para el correlation plot hay que meter dummy variables o si tiene que estar la variable tal cual.
# Tampoco veo que haya mucha correlación entre las variables....
# No sé si hay que hacer la correlación solo del training set, pero lo he hecho de todo...
#As we can see no features are considered correlated, since there are not any value above 0.70 or below -0.70

#Next, we will consider only the statistically significant attributes
#Linear regression:
lm_heart <- lm(cardio ~ ., df)
summary(lm_heart)
#Attributes with p-value<0.5 are selected
paste("By looking at the summary, we can see that the only feature which is not statistically significant is the gender. Thus, we will continue with the rest of the features")

df <- subset(df, select = -c(gender))

#Split data into Train/Test set
library(caret)

set.seed(333) # set random seed for reproducibility
trainIndex <- createDataPartition(df$cardio, p = 0.8, list = FALSE)
train <- df[trainIndex,]
test <- df[-trainIndex,]

#It is convenient to check if the data set is balanced. In case it is extremely unbalanced, it can lead to some issues (good performance predicting predominant class and bad performance with the non-predominant class)
table(train$cardio)
#In this case, we can see it is pretty balanced.
```
#### Classification
```{r}
library(rpart)
library(rpart.plot)
library(randomForest)

#Since this is a classification problem, the first approach we are taking is a decision tree.
# cp_values <- c(0.01, 0.02, 0.03, 0.04, 0.05)
# 
# ctrl <- rpart.control(cp = cp_values, xval = 10, trace = 1)

# model <- rpart(cardio ~ ., data=train, control = ctrl)
# 
# # Crea una lista con los valores de cp y la tasa de error correspondiente en cada iteración del modelo
# cp_values <- data.frame(cp = model$cptable[, "CP"], xerror = model$cptable[, "xerror"])
# 
# # Grafica los valores de cp en un plot
# plot(cp_values$cp, cp_values$xerror, type = "b", xlab = "CP", ylab = "Cross-validation error")
# 
# # Encuentra el valor óptimo de cp y entrena un modelo de árbol de decisión utilizando ese valor
# optimal_cp <- model$cptable[which.min(model$cptable[, "xerror"]),"CP"]
tree <- rpart(cardio ~ ., data = train, method = "class")

rpart.plot(tree)

# Evaluation
heart_pred <- predict(tree, test, type="class")

#heart_pred <- ifelse(heart_pred > 0.5 , 1, 0)
ConfMatrix <- confusionMatrix(as.factor(heart_pred), as.factor(test$cardio))
ConfMatrix

```

```{r}
#Random Forest
train$cardio <- as.factor(train$cardio)
rf <- randomForest(cardio ~ ., data=train)
pred_rf <- predict(rf, test, type="class")

ConfMatrix_Rf <- confusionMatrix(pred_rf, as.factor(test$cardio))
ConfMatrix_Rf

```

```{r}
train_glm <- subset(train, select = -c(gluc2, cholesterol2))
library(dplyr)
#Now, we are going to perform a Logistic regression to compare the results
glm_model <- glm(cardio ~ ., data=train, family = binomial)
glm_pred <- predict(glm_model, newdata=test, type="response")

predicted_classes <- ifelse(glm_pred > 0.5, 1, 0)

accuracy <- mean(predicted_classes == test$cardio)
precision <- sum(predicted_classes == 1 & test$cardio == 1) / sum(predicted_classes == 1)
recall <- sum(predicted_classes == 1 & test$cardio == 1) / sum(test$cardio == 1)
f1_score <- 2 * precision * recall / (precision + recall)

# Print the evaluation metrics
cat("\nAccuracy:", accuracy, "\n")
cat("\nPrecision:", precision, "\n")
cat("\nRecall:", recall, "\n")
cat("\nF1 Score:", f1_score, "\n")

#NO SE MUY BIEN QUE HACER CON LAS DUMMY VARIABLES. AL HACER "SUMMARY(LM_HEART)" CHOLESTEROL2 Y GLUC2 NO TIENEN NI P-VALUE.
#The results from the decision trees, random forest and logistic regression are really similar. 

```

```{r}
library(PRROC)

PRROC_obj <- roc.curve(scores.class0 = pred_rf, weights.class0= test$cardio,curve=TRUE)

plot(PRROC_obj$curve, main="ROC Curve for Three Models", type="l", col="black", xlab="False Positive Rate", ylab="True Positive Rate")

PRROC_obj2 <- roc.curve(scores.class0 = predicted_classes, weights.class0= test$cardio,curve=TRUE)

PRROC_obj3 <- roc.curve(scores.class0 = heart_pred, weights.class0= test$cardio,curve=TRUE)

lines(PRROC_obj$curve, col="blue")

# Add the second ROC curve to the plot
lines(PRROC_obj2$curve, col="green")

# Add the third ROC curve to the plot
lines(PRROC_obj3$curve, col="red")

abline(a=0, b=1, lty=2, col="gray")


# Add a legend to the plot
legend("bottomright", legend=c("Random Forest Model", "Predicted Classes", "Heart Prediction"), col=c("blue", "green", "red"), lty=1, cex=0.8)
```













































